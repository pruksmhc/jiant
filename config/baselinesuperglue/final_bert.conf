include "../defaults.conf"
batch_size = 8
bert_embeddings_mode = "top"
bert_fine_tune = 1
bert_model_name = "bert-large-uncased"
classifier = "log_reg"
classifier_loss_fn = "softmax"
max_seq_len = 510

sent_enc = "null"
sep_embs_for_skip = 1
skip_embs = 1
target_tasks = ""
tokenizer = "bert-base-uncased"
transfer_paradigm = "finetune"
write_preds = "val,test"

elmo = 0 
exp_name = ""
lr_patience = 4
patience = 20
max_vals = 10000
lr = .01
min_lr = .0000001
dropout = 0.1 // following BERT paper
optimizer = bert_adam
do_target_task_training = 1
do_full_eval = 1
val_interval = 200
